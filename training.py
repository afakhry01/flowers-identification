# -*- coding: utf-8 -*-
"""102FlowersDenseNet.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/16GIRoigfSFeO97dJA8lHAsTc3qzECjFT
"""

import numpy as np
import torch
import torch.nn.functional as F
from torch import nn
from torch.utils.data import DataLoader
from torchvision.utils import make_grid
from torchvision.datasets import ImageFolder
from torchvision import transforms, models
import matplotlib.pyplot as plt
import json

device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")

transform_training = transforms.Compose([transforms.Resize((523,500)),
                                         transforms.RandomHorizontalFlip(),
                                         transforms.RandomAffine(0, shear=10, scale=(0.8,1.2)),
                                         transforms.ColorJitter(brightness=0.5, contrast=0.5, saturation=1),
                                         transforms.ToTensor(),
                                         transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
                                        ])

transform = transforms.Compose([transforms.Resize((523,500)),
                               transforms.ToTensor(),
                               transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
                               ])

def tensor2image(tensor):
  image = tensor.cpu().clone().detach().numpy()
  image = image.transpose(1, 2, 0)
  image = image * np.array((0.5, 0.5, 0.5)) + np.array((0.5, 0.5, 0.5))
  image = image.clip(0, 1)
  return image

"""### Download dataset"""

!unzip drive/MyDrive/ML/102FlowersDataset/archive.zip

train_dataset = ImageFolder('flower_data/flower_data/train',transform=transform_training)
valid_dataset = ImageFolder('flower_data/flower_data/valid',transform=transform)
test_dataset  = ImageFolder('test set',transform=transform)
with open('cat_to_name.json') as f:
  cat_to_name = json.load(f)
cat_to_name

print("Number of training images: ",len(train_dataset))
print("Number of validation images: ",len(valid_dataset))
print("Number of testing images: ",len(test_dataset))
print("Number of classes: ",len(train_dataset.classes))

image, label  = train_dataset[0]
fig, ax1 = plt.subplots(figsize=(15,5),nrows=1,ncols=1)
ax1.imshow(tensor2image(image))
ax1.set_title("original image")

batch_size = 64

train_loader = DataLoader(train_dataset, batch_size=batch_size, num_workers=2, shuffle=True, pin_memory=True)
valid_loader = DataLoader(valid_dataset, batch_size=batch_size, num_workers=2, shuffle=True, pin_memory=True)
test_loader  = DataLoader(test_dataset,  batch_size=batch_size, num_workers=2, shuffle=True, pin_memory=True)

for images, labels in train_loader:
    fig, ax = plt.subplots(figsize=(20, 8))
    ax.set_xticks([]); ax.set_yticks([])
    ax.imshow(tensor2image(make_grid(images, nrow=16)))
    break

model =models.densenet121(pretrained=True).to(device)
#model

for param in model.features.parameters():
  param.requires_grad = False

in_features = model.classifier.in_features
last_layer = nn.Linear(in_features, len(cat_to_name))
model.classifier = last_layer
model.to(device)

loss_func = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.parameters(), lr = 0.00001)
epochs = 50

training_loss_history = []
training_corrects_history = []
validation_loss_history = []
validation_corrects_history = []

for epoch in range(epochs):
  
  training_loss = 0.0
  training_correct = 0.0
  validation_loss = 0.0
  validation_correct = 0.0
  
  for inputs, labels in train_loader:
    inputs = inputs.to(device)
    labels = labels.to(device)
    outputs = model(inputs)
    loss = loss_func(outputs, labels)
    
    optimizer.zero_grad()
    loss.backward()
    optimizer.step()
    
    _, preds = torch.max(outputs, 1)
    training_loss += loss.item()
    training_correct += torch.sum(preds == labels.data)

  with torch.no_grad():
    for val_inputs, val_labels in valid_loader:
      val_inputs = val_inputs.to(device)
      val_labels = val_labels.to(device)
      val_outputs = model(val_inputs)
      val_loss = loss_func(val_outputs, val_labels)
      
      _, val_preds = torch.max(val_outputs, 1)
      validation_loss += val_loss.item()
      validation_correct += torch.sum(val_preds == val_labels.data)
      
    epoch_loss = training_loss/len(train_loader.dataset)
    epoch_acc = training_correct.float()/ len(train_loader.dataset)

    training_loss_history.append(epoch_loss)
    training_corrects_history.append(epoch_acc)
    
    val_epoch_loss = validation_loss/len(valid_loader.dataset)
    val_epoch_acc = validation_correct.float()/ len(valid_loader.dataset)
    validation_loss_history.append(val_epoch_loss)
    validation_corrects_history.append(val_epoch_acc)

    print("Epoch [{}], train_loss: {:.4f}, train_acc: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}".format(epoch, epoch_loss, epoch_acc, val_epoch_loss, val_epoch_acc))

training_loss_history_2 = [x for x in training_loss_history]
validation_loss_history_2 = [x for x in validation_loss_history]

training_corrects_history_2 = [x for x in training_corrects_history]
validation_corrects_history_2 = [x for x in validation_corrects_history]

plt.plot(training_loss_history, label='training loss')
plt.plot(validation_loss_history, label='validation loss')
plt.legend()

plt.plot(training_corrects_history, label='training accuracy')
plt.plot(validation_corrects_history, label='validation accuracy')
plt.legend()

iterator = iter(valid_loader)
images, labels = iterator.next()
images = images.to(device)
labels = labels.to(device)
output = model(images)
_, preds = torch.max(output, 1)

fig = plt.figure(figsize=(30, 4))

for ndx in np.arange(20):
  img = fig.add_subplot(2, 10, ndx+1, xticks=[], yticks=[])
  plt.imshow(tensor2image(images[ndx]))
  img.set_title("{} ({})".format(cat_to_name[str(preds[ndx].item())], cat_to_name[str(labels[ndx].item())]), color=("green" if preds[ndx]==labels[ndx] else "red"))

torch.save(model.state_dict(), "plants_classification_cnn.pt")
!cp plants_classification_cnn.pt drive/MyDrive/ML/102FlowersDataset/plants_classification_cnn_dense_100_epochs.pt

